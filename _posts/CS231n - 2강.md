---
layout: post
title: "CS231n- 2강"
subtitle: "data"
categories: Data
tags: cs231n
comments: true
---



## CS231n

##  2) Image Classfication pipline



### 이미지 분류 - computer vision의 핵심



### 이미지 classfication이 가능해야 => detection, Segmentation, Image captioning 가능 



이미지는 숫자로 구성되어 있다

300*100*3(height width colorchannel)



Classfier challenge:

 시각에 따른 변화/조명/형태의변형/은폐은닉(occlusion)/background clutter/Intraclass variation



Classfier 기본함수



def predict(image):

​	return class_label



이미지 예측 -> 이미지 label



숫자를 분류하는 것과 다르게 이미지 구분에는 명백한 알고리즘이 없다



data-driven approach



image and label - train image classfier - test image classifer



First classfier - Nearest Neigbor Classfier



Remember all training images and their labels in Memory

Predict the label of the most similar trainging image by metric distance





Example -CIFAR 10

10 labels

50000 trainging images 

10000 test images



How to Compare?

1. L1(Manhattan)  distance
2. L2(Euclidean)  distance



NN Classfier linearly depend on the size of the train data

-> ANN,FLANN 이용해 속도 높이기



-Hyperparameter -> 실험을 통해서 알아보기

 - what is the best distance to use?

- what is the best value of k to use?

  => Must try alll



train -> test : bad idea, Test set use only at the end



train -> validation data(from train data) -> test data :

   => use Cross validation 



k-NN never used 



terrible performace at test time

distance metric are not very unintutive



Linear Classfication

- Parametirc approach
  - f(x,W)    x : image/W : parameters
  - f(x,W)(10 * 1) = W(10 * 3072)x(3072 * 1)+b(10 * 1)









